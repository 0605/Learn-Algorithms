

/////////////////// 海量数据处理(千万以上量级)  ///////////


2.有一千万条短信，有重复，以文本文件的形式保存，一行一条，有重复。
请用5分钟时间，找出重复出现最多的前10条。



3.大量的URL字符串，如何从中去除重复的，优化时间空间复杂度

 

2.一个文件，内含一千万行字符串，每个字符串在1K以内，
要求找出所有相反的串对，如abc和cba。

 

2.给出一个文件，里面包含两个字段{url、size}，
即url为网址，size为对应网址访问的次数，
要求：
问题1、利用Linux Shell命令或自己设计算法，
查询出url字符串中包含“baidu”子字符串对应的size字段值；
问题2、根据问题1的查询结果，对其按照size由大到小的排列。
（说明：url数据量很大，100亿级以上）
 

 

3.有10个文件，每个文件1G，
每个文件的每一行都存放的是用户的query，每个文件的query都可能重复。
要求按照query的频度排序.

 

2.有一个很大很大的输入流，大到没有存储器可以将其存储下来，而且只输入一次，如何从这个输入流中随机取得m个记录




31、在一个文件中有 10G 个整数，乱序排列，要求找出中位数。内存限制为 2G。只写出思路即可。



32、一个文件中有40亿个整数，每个整数为四个字节，内存为1GB，写出一个算法：求出这个文件里的整数里不包含的一个整数


33、腾讯服务器每秒有2w个QQ号同时上线，找出5min内重新登入的qq号并打印出来。




淘宝面试题：有一个一亿节点的树，现在已知两个点，找这两个点的共同的祖先。
海量数据分布在100台电脑中，想个办法高效统计出这批数据的TOP10。（此题请参考本博客内其它文章）。
某服务器流量统计器，每天有1000亿的访问记录数据，包括时间、url、ip。设计系统实现记录数据的

保存、管理、查询。要求能实现一下功能：
（1）计算在某一时间段（精确到分）时间内的，某url的所有访问量。
（2）计算在某一时间段（精确到分）时间内的，某ip的所有访问量。

 

假设某个网站每天有超过10亿次的页面访问量，出于安全考虑，网站会记录访问客户端访问的ip地址和对应的时间，如果现在已经记录了1000亿条数据，想统计一个指定时间段内的区域ip地址访问量，那么这些数据应该按照何种方式来组织，才能尽快满足上面的统计需求呢，
设计完方案后，并指出该方案的优缺点，比如在什么情况下，可能会非常慢？（参考答案：用B+树来组织，非叶子节点存储（某个时间点，页面访问量），叶子节点是访问的IP地址。这个方案的优点是查询某个时间段内的IP访问量很快，但是要统计某个IP的访问次数或是上次访问时间就不得不遍历整个树的叶子节点。或者可以建立二级索引，分别是时间和地点来建立索引。）

 

腾讯1.服务器内存1G，有一个2G的文件，里面每行存着一个QQ号（5-10位数），怎么最快找出出现过最多次的QQ号。（此题与稍后下文的第14题重复，思路参考请见下文第14题）。





18、如何随机选取1000个关键字
给定一个数据流，其中包含无穷尽的搜索关键字（比如，人们在谷歌搜索时不断输入的关键字）。如何才能从这个无穷尽的流中随机的选取1000个关键字？





14、腾讯最新面试题：服务器内存1G，有一个2G的文件，里面每行存着一个QQ号（5-10位数），怎么最快找出出现过最多次的QQ号。

以下是个人所建第Algorithms_12群内朋友的聊天记录：

    首先你要注意到，数据存在服务器，存储不了（内存存不了），要想办法统计每一个qq出现的次数。
比如，因为内存是1g，首先 你用hash 的方法，把qq分配到10个（这个数字可以变动，比较）文件（在硬盘中）。
    相同的qq肯定在同一个文件中，然后对每一个文件，只要保证每一个文件少于1g的内存，统计每个qq的次数，可以使用hash_map(qq, qq_count)实现。然后，记录每个文件的最大访问次数的qq，最后，从10个文件中找出一个最大，即为所有的最大。更多读者可以参见此文：海量数据处理面试题集锦与Bit-map详解 。

    那若面试官问有没有更高效率的解法之类的?这时，你可以优化一下，但是这个速度很快，hash函数，速度很快，他肯定会问，你如何设计，用bitmap也行。


